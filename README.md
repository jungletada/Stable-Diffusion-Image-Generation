# Stable-Diffusion-Image-Generation
主要研究inpaint，outpaint，replacement
## 相关文献
### 对比学习相关
目前还没看到把对比学习用在Stable Diffusion上
- 对比对抗学习条件图像生成 [Github NeurIPS2020](https://github.com/POSTECH-CVLab/PyTorch-StudioGAN)  
[ContraGAN: Contrastive Learning for Conditional Image Generation](https://proceedings.neurips.cc/paper/2020/file/f490c742cd8318b8ee6dca10af2a163f-Paper.pdf)  

- 对比对抗学习条件图像生成 [Github CVPR2021](https://github.com/ruiliu-ai/DivCo)  
[DivCo: Diverse Conditional Image Synthesis via Contrastive Generative Adversarial Network](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_DivCo_Diverse_Conditional_Image_Synthesis_via_Contrastive_Generative_Adversarial_Network_CVPR_2021_paper.pdf)

### 图像编辑相关
- DDPM Inpainting [Github CVPR2022](https://github.com/andreas128/RePaint)  
[RePaint: Inpainting using Denoising Diffusion Probabilistic Models](https://openaccess.thecvf.com/content/CVPR2022/papers/Lugmayr_RePaint_Inpainting_Using_Denoising_Diffusion_Probabilistic_Models_CVPR_2022_paper.pdf)

- T2I-Adapter [Github AAAI2024](https://ojs.aaai.org/index.php/AAAI/article/view/28226)  
[T2I-Adapter: Learning Adapters to Dig Out More Controllable Ability for Text-to-Image Diffusion Models](https://github.com/TencentARC/T2I-Adapter)

- Diffusion Self-Guidance [Project NeurIPS2023](https://dave.ml/selfguidance/)  
[Diffusion Self-Guidance for Controllable Image Generation](https://proceedings.neurips.cc/paper_files/paper/2023/hash/3469b211b829b39d2b0cfd3b880a869c-Abstract-Conference.html)


- BLIP-Diffusion [Github NeurIPS2023](https://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion)    
[BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing](https://proceedings.neurips.cc/paper_files/paper/2023/hash/602e1a5de9c47df34cae39353a7f5bb1-Abstract-Conference.html)

- Uni-ControlNet [Github NeurIPS2023](https://github.com/ShihaoZhaoZSH/Uni-ControlNet)  
[Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models](https://proceedings.neurips.cc/paper_files/paper/2023/hash/2468f84a13ff8bb6767a67518fb596eb-Abstract-Conference.html)

- PnP-diffusion-features [CVPR2023](https://pnp-diffusion.github.io/)  
[Plug-and-play diffusion features for text-driven image-to-image translation](https://openaccess.thecvf.com/content/CVPR2023/html/Tumanyan_Plug-and-Play_Diffusion_Features_for_Text-Driven_Image-to-Image_Translation_CVPR_2023_paper.html)

- Diffusion Models综述 ACM Journals    
[Diffusion Models: A Comprehensive Survey of Methods and Applications](https://dl.acm.org/doi/full/10.1145/3626235?casa_token=1h3b6MvPrhAAAAAA%3AtRsfu8YR2s1kLVdI_AfXKJuVt8w0H6vX_IpRJ01_TAyqHK6iJoqjOEj3r7xTsbqsb7SvQHvpnVPv)

